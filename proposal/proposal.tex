\documentclass[letterpaper,twocolumn,11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{scs}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{amssymb,amsmath}
\usepackage{url}
\usepackage{multicol}

% title: - TBD
\title{Title-To Be Decided}
%{Scene Classification with Deep Convolutional Neural Networks}
%{Deep Convolutional Neural Networks for Recognizing Natural Scene Categories}
\author{The Author}
\date{} % Activate to display a given date or no date

\begin{document}
\maketitle

% overview: describe the problem and main idea
\section{Problem}
	Developing robust and geometrically invariant object representation for
	recognizing the semantic category of an image remains a challenging problem
	for computer vision and machine intelligence. In this project, we are
	attempting to recognize the	semantic category of an	image by using deep
	convolutional neural networks based on "spatial pyramid".

% related work: briefly describe related papers
\section{Previous Work}
TODO

% technical approach: describe the feature representation(s) and algorithm(s)
\section{Approach}
\par
	A. Krizhevsky et al.\cite{CNN} trained a large, deep convolutional neural
	network used for classifying high-resolution images in ImageNet contest
	and obtained impressive results for highly challenging object recognition
	tasks using	supervised learning. The features used in this technique can
	be a good candidate for natural scene categories.

\par
	Selective search\cite{SS} is an algorithm that aims to capture all possible
	object locations by enabling the use of the powerful Bag-of-Words model
	for recognition. This algorithm can help us significantly reduce the total
	processing time without lose much overall performance.

\par
	After we obtain the possible object locations using selective search,
	constructing of three-level pyramid allows us to precisely matching of two
	collections of features in a high-dimensional appearance space despite
	of the spatial information.\cite{SPM}

\par
	As for the classification, the first thing we planning to attempt is a
	linear support vector machine (SVM).\cite{SVM} There is some useful
	open source SVM libraries that are publicly available to use.

% experiments: Describe the experiments to evaluate your approach
\section{Experiments}
TODO

% others: describe software, libraries, language that you will use
% and how you plan to share the work with your partner.
\section{Matirials}
	\subsection{Dataset}
	\begin{itemize}
	\item{IndoorCVPR\_09} is a challenging dataset which contains 67
	indoor categories and a total of 15,620 images. To address these indoor
	scenes recognition, we need a model	that can exploit local and global
	discriminative information.\cite{DATA}
	\end{itemize}
	\subsection{Tools}
	\begin{itemize}
	\item{Caffe} is a high-performance deep learning framework with GPU
	acceleration. \cite{CAFFE}

	\item{Selective Search Software} code is publicly available to use
	for capture possible locations for object recognition. \cite{SS}

	\item{LibSVM} is a library for SVM classification. \cite{SVM}
	\end{itemize}

% references:
\begin{thebibliography}{10}

\bibitem{CNN} A. Krizhevsky, I. Sutskever, and G. Hinton.,
"ImageNet Classification with Deep Convolutional Neural Networks",
NIPS 2012.

\bibitem{SS} J. R. R. Uijlings, K. E. A. van de Sande,
T. Gevers, A. W. M. Smelters
"Selective Search for Object Recognition",
\emph{In International Journal of Computer Vision}, 2013.

\bibitem{SPM} S. Lazebnik, C. Schmid, and J. Ponce.,
"Beyond Bags of Features:
Spatial Pyramid Matching for Recognizing Natural Scene Categories",
CVPR 2006.

\bibitem{OB} L-J. Li, H. Su, E. Xing, and L. Fei-Fei.,
"Object Bank: A High-Level Image Representation for Scene Classification
\& Semantic Feature Sparsification",
NIPS 2010.

\bibitem{DATA} A. Quattoni, and A.Torralba. Recognizing Indoor Scenes.
\emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
2009.

\bibitem{SVM} LibSVM: http://www.csie.ntu.edu.tw/~cjlin/libsvm/

\bibitem{CAFFE} Caffe: http://caffe.berkeleyvision.org/


\end{thebibliography}
\end{document}