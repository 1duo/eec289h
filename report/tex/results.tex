%Describe the experiments you conducted to evaluate the approach.  For each
%experiment, describe what you did, what was the main purpose of the experiment,
%and what you learned from the results. Provide figures, tables, and qualitative
%examples, as appropriate.

In this section, we evaluate our method on the MIT-indoor67 dataset. Suggested training and
testing list of images are used to do the training (80 images per class) and validation (20
images per class), all images are in jpeg format.

Multi-class classification is done with a 67 SVMs trained using one-versus-all rule, that is, each
classifier is learned to separate each class from the rest of classes. Test image is assigned the
label of the class with the highest confidence score. Scene classification performance is
evaluated by the average multi-class classification accuracy over all scene classes.

For comparison purpose, we implement with the same procedure but only use
the extracted layer 7 4096-dimensional feature vectors from Caffe. After we get
one feature vectors for each entire image, instead of perform spatial pyramid
and L2 normalization, we simply add labels and send them into the multi-class
SVMs. Validation image feature vectors are also generated in the same way.

% Table 1
\begin{table*}[ht]
	\caption{Comparison results on MIT-indoor67}
	\centering
	\begin{tabular}{l c c}
	\hline \hline
	Models                & Average Precision \\ \hline
	$l2$ Norm + Selective Search + Spatial Pyramid & {\bf{68.2953\%}} \\
	Selective Search + Spatial Pyramid & 68.0469\% \\
        Entire Image CNN Features & 59.9507\% \\
	\hline
	\end{tabular}
	\label{tab:overall}
\end{table*}

We compare our scene classification performance with two other methods: 1) using only the
features extracted from the entire image; 2) using selective search and spatial pyramid, but without the
$l2$ normalization. The summary of our performance comparison is listed in Table~\ref{tab:overall}.
Our method achieves a mean average precision (mAP) of 68.2953\% on dataset
MIT-indoor67. For comparison, we implement the same method using only 4096-dimensional
feature vectors extracted from Caffe without region proposals, spatial pyramid, and max-pooling.
Using selective search and spatial pyramid gives us a 8.1\% performance gain and introducing
the $l2$ normalization gives us an extra 0.25\% performance gain. In most categories, we perform much
better on the average precision. Some examples are shoes shop, bedroom, bowling, grocery store, hospital room and operating
room. This might due to the region proposals and spatial pyramid technique
allow us to better characterize the particular objects belong to the category.
However, there are also some drops of average accuracy using our methods and
mainly for these three categories: prison-cell, library and living room. These
three categories are all relatively easier to be characterized by global
spatial properties.
\yzh{Need to talk more about the performance difference for different categories. Will update this after Yuduo put the
new chart on.}

\iffalse
% Table 2
\begin{table}[ht]
        \caption{Average Acurracy that Drops}
        \centering
        \begin{tabular}{l c c}
        \hline \hline
        Category    & our method & only feature \\ \hline
        prison-cell & 45\%       & 70\% \\
        library     & 45\%       & 70\% \\
        livingroom  & 20\%       & 40\% \\
        \hline
        \end{tabular}
        \label{tab:overall}
\end{table}
\fi
% compare with other paper results

% heatmap visulizations
