% briefly summarize the main idea and results, and possible future work.

This report has presented a novel approach for scene classification based on
deep convolutional neural networks. We try to fill in the semantic gap between
the large deep convolutional neural network features from the massive dataset
like ImageNet and the high-level context in the scene categories. Our method, which
works by extracting spatial pyramid features from region proposals of images, has shown
that deep convolutional neural network is capable of achieving promising
results on highly challenging, large-scale dataset which contains both scenes
that can be well characterized by global spatial properties and the scenes that
can be well characterized by detailed objects they contains.
It is notable and significant that we achieved these results by using a
combination of classical computer vision approaches and deep convolutional
neural networks.

Future works include: Combining the 4096-dimensional feature vector of predicting
the entire image in the ImageNet-CNN and the last two levels of spatial parymid
deep features in order to preserve both global image information and visual information
come from various region proposals; Testing our method on more datasets to show our
generality; Improving the performance of CNN by constructing/changing layers and parameters
per layer, and training the CNN on better organized dataset.