\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{42} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Scene Classification with Deep Convolutional Neural Networks}

\author{Yangzihao Wang\\
University of California, Davis\\
{\tt\small yzhwang@ucdavis.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Yuduo Wu\\
University of California, Davis\\
{\tt\small yudwu@ucdavis.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
%summarize the problem, main idea, and results;
The use of massive datasets like ImageNet and the revival of Convolutional
Neural Networks (CNNs) for learning deep features has significantly improved
the performance of object recognition. However, performance at scene
classification has not achieved the same level of success since there is still
semantic gap between the deep features and the high-level context.  In this
project we proposed a novel scene classification method which combines CNN and
Spatial Pyramid to generate high-level context-aware features for one-vs-all
linear SVMs. Our method achieves the state-of-the-art result: 68.04\% average
accuracy rate on MIT indoor67 dataset using only the deep features trained from
ImageNet.

\end{abstract}

%%%%%%%%% BODY TEXT
\section{Related Work}
\label{sec:related}
\input{tex/related}

%%%%%%%%% BODY TEXT
\section{Technical Approach}
\label{sec:method}
\input{tex/method}

\section{Experiments}
\label{sec:results}
\input{tex/results}

%-------------------------------------------------------------------------
\section{Conclusions}

briefly summarize the main idea and results, and possible future work.

{\small
\bibliographystyle{ieee}
\bibliography{report}
}

\end{document}