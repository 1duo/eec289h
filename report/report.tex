\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{42} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Scene Classification with Deep Convolutional Neural Networks}

\author{Yangzihao Wang\\
University of California, Davis\\
{\tt\small yzhwang@ucdavis.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Yuduo Wu\\
University of California, Davis\\
{\tt\small yudwu@ucdavis.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
%summarize the problem, main idea, and results;
The use of massive datasets like ImageNet and the revival of Convolutional
Neural Networks (CNNs) for learning deep features has significantly improved
the performance of object recognition. However, performance at scene
classification has not achieved the same level of success since there is still
semantic gap between the deep features and the high-level context.  In this
project we proposed a novel scene classification method which combines CNN and
Spatial Pyramid to generate high-level context-aware features for one-vs-all
linear SVMs. Our method achieves the state-of-the-art result: 68.04\% accuracy
rate on MIT indoor67 dataset using only the deep features trained from
ImageNet. 
 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Related Work}
\label{sec:related}
\input{tex/related}

\subsection{Technical Approach}

Describe in detail the feature representation(s) and algorithm(s) you employed.
The description should be self-contained (i.e., the reader should not have to
rely on outside sources for your points to be clear), and should provide enough
detail so that the reader could re-implement the approach.  Clearly state the
method's input and output, and any assumptions or design choices;

\subsection{Experiments}

Describe the experiments you conducted to evaluate the approach.  For each
experiment, describe what you did, what was the main purpose of the experiment,
and what you learned from the results. Provide figures, tables, and qualitative
examples, as appropriate.

%-------------------------------------------------------------------------
\subsection{Conclusions}

briefly summarize the main idea and results, and possible future work.

{\small
\bibliographystyle{ieee}
\bibliography{report}
}

\end{document}
